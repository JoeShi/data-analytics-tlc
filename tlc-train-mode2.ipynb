{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb84f2fd",
   "metadata": {},
   "source": [
    "# Train TLC Demands Predicator with SageMaker AutoGluon Tabular"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "775e84ba",
   "metadata": {},
   "source": [
    "[AutoGluon](https://github.com/awslabs/autogluon) automates machine learning tasks enabling you to easily achieve strong predictive performance in your applications. With just a few lines of code, you can train and deploy high-accuracy deep learning models on tabular, image, and text data.\n",
    "This example shows how to use AutoGluon-Tabular with Amazon SageMaker by applying [pre-built deep learning containers](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4992c4f",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf25796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "from ag_model import (\n",
    "    AutoGluonSagemakerEstimator,\n",
    "    AutoGluonNonRepackInferenceModel,\n",
    "    AutoGluonSagemakerInferenceModel,\n",
    "    AutoGluonRealtimePredictor,\n",
    "    AutoGluonBatchPredictor,\n",
    ")\n",
    "from sagemaker import utils\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "role = \"arn:aws:iam::178770047227:role/service-role/SageMaker-ExecutionRole-20231202T212840\" # change to your role\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session._region_name\n",
    "\n",
    "bucket = \"qiaoshi-aws-ml\"\n",
    "s3_prefix = f\"tlc/ml/{utils.sagemaker_timestamp()}\"\n",
    "output_path = f\"s3://{bucket}/{s3_prefix}/output/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8213590f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b453761",
   "metadata": {},
   "source": [
    "Users can create their own training/inference scripts using [SageMaker Python SDK examples](https://sagemaker.readthedocs.io/en/stable/overview.html#prepare-a-training-script).\n",
    "The scripts we created allow to pass AutoGluon configuration as a YAML file (located in `data/config` directory).\n",
    "\n",
    "We are using [official AutoGluon Deep Learning Container images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers) with custom training scripts (see `scripts/` directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da167200",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AutoGluonSagemakerEstimator(\n",
    "    role=role,\n",
    "    entry_point=\"scripts/tabular_train.py\",\n",
    "    region=region,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.8xlarge\",\n",
    "    framework_version=\"0.8.2\",\n",
    "    py_version=\"py39\",\n",
    "    base_job_name=\"tlc-tabular-train\",\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69870f34",
   "metadata": {},
   "source": [
    "Upload the data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204a60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = f\"autogluon_sm/{utils.sagemaker_timestamp()}\"\n",
    "\n",
    "train_input = \"s3://qiaoshi-aws-ml/tlc/results/ml/trips_with_weather_merged/train.csv\"\n",
    "\n",
    "eval_input = \"s3://qiaoshi-aws-ml/tlc/results/ml/trips_with_weather_merged/eval.csv\"\n",
    "\n",
    "\n",
    "config_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"config\", \"config-med.yaml\"), key_prefix=s3_prefix\n",
    ")\n",
    "\n",
    "# Provide inference script so the script repacking is not needed later\n",
    "# See more here: https://docs.aws.amazon.com/sagemaker/latest/dg/mlopsfaq.html\n",
    "# Q. Why do I see a repack step in my SageMaker pipeline?\n",
    "inference_script = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"scripts\", \"tabular_serve.py\"), key_prefix=s3_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f420b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://qiaoshi-aws-ml/tlc/results/ml/trips_with_weather_merged/eval.csv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a9cce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-178770047227/autogluon_sm/2024-01-17-03-44-57-240/config-med.yaml'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fedb3195",
   "metadata": {},
   "source": [
    "### Fit The Model\n",
    "For local training set `instance_type` to local.\n",
    "\n",
    "For non-local training the recommended instance type is `ml.m5.2xlarge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "794ea738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tlc-training-1705463118-1fb3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-17 03:45:21 Starting - Starting the training job...\n",
      "2024-01-17 03:45:35 Starting - Preparing the instances for training......\n",
      "2024-01-17 03:46:51 Downloading - Downloading input data......\n",
      "2024-01-17 03:47:46 Downloading - Downloading the training image...\n",
      "2024-01-17 03:48:30 Training - Training image download completed. Training in progress...bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-01-17 03:48:53,284 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-01-17 03:48:53,286 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-01-17 03:48:53,288 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-01-17 03:48:53,299 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-01-17 03:48:53,301 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-01-17 03:48:53,546 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-01-17 03:48:53,548 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-01-17 03:48:53,562 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-01-17 03:48:53,564 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-01-17 03:48:53,577 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "2024-01-17 03:48:53,580 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-01-17 03:48:53,592 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"config\": \"/opt/ml/input/data/config\",\n",
      "        \"serving\": \"/opt/ml/input/data/serving\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"config\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"serving\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"tlc-training-1705463118-1fb3\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-178770047227/tlc-training-1705463118-1fb3/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"tabular_train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"tabular_train.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={}\n",
      "SM_USER_ENTRY_POINT=tabular_train.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"serving\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"config\",\"serving\",\"test\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.m5.2xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=tabular_train\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=8\n",
      "SM_NUM_GPUS=0\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=s3://sagemaker-us-east-1-178770047227/tlc-training-1705463118-1fb3/source/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"serving\":\"/opt/ml/input/data/serving\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"serving\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"tlc-training-1705463118-1fb3\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-178770047227/tlc-training-1705463118-1fb3/source/sourcedir.tar.gz\",\"module_name\":\"tabular_train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"tabular_train.py\"}\n",
      "SM_USER_ARGS=[]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_CONFIG=/opt/ml/input/data/config\n",
      "SM_CHANNEL_SERVING=/opt/ml/input/data/serving\n",
      "SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.9 tabular_train.py\n",
      "2024-01-17 03:48:54,496 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Starting AG\n",
      "Args: Namespace(output_data_dir='/opt/ml/output/data', model_dir='/opt/ml/model', n_gpus='0', train_dir='/opt/ml/input/data/train', test_dir='/opt/ml/input/data/test', ag_config='/opt/ml/input/data/config', serving_script='/opt/ml/input/data/serving')\n",
      "Using config-med.yaml\n",
      "Running training job with the config:\n",
      "{'ag_fit_args':\n",
      "{'num_bag_folds': 2,\n",
      "                 'num_bag_sets': 1,\n",
      "                 'num_stack_levels': 0,\n",
      "                 'presets'\n",
      ": 'medium_quality_faster_train'},\n",
      " 'ag_predictor_args':\n",
      "{'label': 'total_trips', 'problem_type': 'regression'},\n",
      " 'feature_importance': True,\n",
      " 'leaderboard': True,\n",
      " 'num_gpus': 0,\n",
      " 'output_prediction_format': 'csv'}\n",
      "Using train.csv\n",
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/opt/ml/model\"\n",
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Warning: Training may take a very long time because `time_limit` was not specified and `train_data` is large (7761323 samples, 2237.31 MB).\n",
      "#011Consider setting `time_limit` to ensure training finishes within an expected duration or experiment with a small portion of `train_data` to identify an ideal `presets` and `hyperparameters` configuration.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/opt/ml/model/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Nov 4 16:55:14 UTC 2023\n",
      "Disk Space Avail:   28.80 GB / 31.53 GB (91.4%)\n",
      "Train Data Rows:    7761323\n",
      "Train Data Columns: 25\n",
      "Label Column: total_trips\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Available Memory:                    28757.03 MB\n",
      "#011Train Data (Original)  Memory Usage: 2175.22 MB (7.6% of available memory)\n",
      "Warning: Data size prior to feature transformation consumes 7.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Stage 1 Generators:\n",
      "#011#011Fitting AsTypeFeatureGenerator...\n",
      "Note: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "Stage 2 Generators:\n",
      "#011#011Fitting FillNaFeatureGenerator...\n",
      "Stage 3 Generators:\n",
      "#011#011Fitting IdentityFeatureGenerator...\n",
      "Fitting CategoryFeatureGenerator...\n",
      "Fitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "Stage 4 Generators:\n",
      "#011#011Fitting DropUniqueFeatureGenerator...\n",
      "Stage 5 Generators:\n",
      "#011#011Fitting DropDuplicatesFeatureGenerator...\n",
      "Types of features in original data (raw dtype, special dtypes):\n",
      "#011#011('bool', [])   :  1 | ['is_holiday']\n",
      "('float', [])  : 16 | ['humidity', 'precipprob', 'winddir', 'sealevelpressure', 'cloudcover', ...]\n",
      "#011#011('int', [])    :  6 | ['year', 'month', 'day', 'hour', 'PULocationID', ...]\n",
      "('object', []) :  2 | ['preciptype', 'icon']\n",
      "#011Types of features in processed data (raw dtype, special dtypes):\n",
      "#011#011('category', [])  :  2 | ['preciptype', 'icon']\n",
      "#011#011('float', [])     : 16 | ['humidity', 'precipprob', 'winddir', 'sealevelpressure', 'cloudcover', ...]\n",
      "#011#011('int', [])       :  6 | ['year', 'month', 'day', 'hour', 'PULocationID', ...]\n",
      "#011#011('int', ['bool']) :  1 | ['is_holiday']\n",
      "24.5s = Fit runtime\n",
      "#01125 features in original data used to generate 25 features in processed data.\n",
      "Train Data (Processed) Memory Usage: 1389.28 MB (4.8% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 26.93s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "#011This metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "#011To change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "#011'NN_TORCH': {},\n",
      "#011'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "#011'CAT': {},\n",
      "#011'XGB': {},\n",
      "#011'FASTAI': {},\n",
      "#011'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "#011'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "#011'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "Warning: Not enough memory to safely train model. Estimated to require 2.794 GB out of 28.183 GB available memory (49.570%)... (20.000% of avail memory is the max safe size)\n",
      "#011To force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.55 to avoid the error)\n",
      "#011#011To set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "#011Not enough memory to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "Warning: Not enough memory to safely train model. Estimated to require 2.794 GB out of 28.182 GB available memory (49.572%)... (20.000% of avail memory is the max safe size)\n",
      "#011To force training the model, specify the model hyperparameter \"ag.max_memory_usage_ratio\" to a larger value (currently 1.0, set to >=0.55 to avoid the error)\n",
      "#011#011To set the same value for all models, do the following when calling predictor.fit: `predictor.fit(..., ag_args_fit={\"ag.max_memory_usage_ratio\": VALUE})`\n",
      "#011Not enough memory to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "Memory not enough to fit LGBModel folds in parallel. Will do sequential fitting instead. #011Consider decreasing folds trained in parallel by passing num_folds_parallel to ag_args_ensemble when calling predictor.fit\n",
      "#011Fitting 2 child models (S1F1 - S1F2) | Fitting with SequentialLocalFoldFittingStrategy\n",
      "[1000]#011valid_set's rmse: 87.4596\n"
     ]
    }
   ],
   "source": [
    "job_name = utils.unique_name_from_base(\"tlc-training\")\n",
    "ag.fit(\n",
    "    {\n",
    "        \"config\": config_input,\n",
    "        \"train\": train_input,\n",
    "        \"test\": eval_input,\n",
    "        \"serving\": inference_script,\n",
    "    },\n",
    "    job_name=job_name,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4d57c00",
   "metadata": {},
   "source": [
    "### Model export\n",
    "\n",
    "AutoGluon models are portable: everything needed to deploy a trained model is in the tarball created by SageMaker.\n",
    "\n",
    "The artifact can be used locally, on EC2/ECS/EKS or served via SageMaker Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {ag.model_data} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240c86b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls -alF model.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7633d597",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Endpoint Deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb4fb9ec",
   "metadata": {},
   "source": [
    "Upload the model we trained earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6eaa2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.utils.unique_name_from_base(\"sagemaker-autogluon-serving-trained-model\")\n",
    "\n",
    "model_data = sagemaker_session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4c9a075",
   "metadata": {},
   "source": [
    "Deploy remote or local endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6dd02",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\"\n",
    "# instance_type = 'local'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49533e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoGluonNonRepackInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.6\",\n",
    "    py_version=\"py38\",\n",
    "    instance_type=instance_type,\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"tabular_serve.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e333d24",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.deploy(initial_instance_count=1, serializer=CSVSerializer(), instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30190a41-71df-4eca-a616-a32ee9b5b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = AutoGluonRealtimePredictor(model.endpoint_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52982b98",
   "metadata": {},
   "source": [
    "### Predict on unlabeled test data\n",
    "\n",
    "Remove target variable (`class`) from the data and get predictions for a sample of 100 rows using the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3fab4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/test.csv\")\n",
    "data = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ab16a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds = predictor.predict(data.drop(columns=\"class\"))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a8ab4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = preds[[\"pred\"]]\n",
    "p = p.join(data[\"class\"]).rename(columns={\"class\": \"actual\"})\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9dcbe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{(p.pred==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "084ee65e",
   "metadata": {},
   "source": [
    "### Cleanup Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd315e3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8197080",
   "metadata": {},
   "source": [
    "# Batch Transform\n",
    "\n",
    "Deploying a trained model to a hosted endpoint has been available in SageMaker since launch and is a great way to provide real-time predictions to a service like a website or mobile app. But, if the goal is to generate predictions from a trained model on a large dataset where minimizing latency isnâ€™t a concern, then the batch transform functionality may be easier, more scalable, and more appropriate.\n",
    "\n",
    "[Read more about Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b607438",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.utils.unique_name_from_base(\n",
    "    \"sagemaker-autogluon-batch_transform-trained-model\"\n",
    ")\n",
    "\n",
    "model_data = sagemaker_session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab078513",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88630d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoGluonSagemakerInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.6\",\n",
    "    py_version=\"py38\",\n",
    "    instance_type=instance_type,\n",
    "    entry_point=\"tabular_serve-batch.py\",\n",
    "    source_dir=\"scripts\",\n",
    "    predictor_cls=AutoGluonBatchPredictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fd30b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    strategy=\"MultiRecord\",\n",
    "    max_payload=6,\n",
    "    max_concurrent_transforms=1,\n",
    "    output_path=output_path,\n",
    "    accept=\"application/json\",\n",
    "    assemble_with=\"Line\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9559625",
   "metadata": {},
   "source": [
    "Prepare data for batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dde772",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(f\"data/test.csv\")[:100].to_csv(\"data/test_no_header.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "355fabc8",
   "metadata": {},
   "source": [
    "Upload data to sagemaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3dbd00",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_input = transformer.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"data\", \"test_no_header.csv\"), key_prefix=s3_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b56f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformer.transform(\n",
    "    test_input,\n",
    "    input_filter=\"$[:14]\",  # filter-out target variable\n",
    "    split_type=\"Line\",\n",
    "    content_type=\"text/csv\",\n",
    "    output_filter=\"$['class']\",  # keep only prediction class in the output\n",
    ")\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee44ccfb",
   "metadata": {},
   "source": [
    "Download batch transform outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ff698",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {transformer.output_path[:-1]}/test_no_header.csv.out ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b0953",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = pd.concat(\n",
    "    [\n",
    "        pd.read_json(\"test_no_header.csv.out\", orient=\"index\")\n",
    "        .sort_index()\n",
    "        .rename(columns={0: \"preds\"}),\n",
    "        pd.read_csv(\"data/test.csv\")[[\"class\"]].iloc[:100].rename(columns={\"class\": \"actual\"}),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150fa02",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{(p.preds==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd3e9e5a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "In this tutorial we successfully trained an AutoGluon model and explored a few options how to deploy it using SageMaker. Any of the sections of this tutorial (training/endpoint inference/batch inference) can be used independently (i.e. train locally, deploy to SageMaker, or vice versa).\n",
    "\n",
    "Next steps:\n",
    "* [Learn more](https://auto.gluon.ai) about AutoGluon, explore [tutorials](https://auto.gluon.ai/stable/tutorials/index.html).\n",
    "* Explore [SageMaker inference documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
