{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb84f2fd",
   "metadata": {},
   "source": [
    "# Train TLC Trip Demands Predicator\n",
    "\n",
    "In this notebook, we will train a model to predict the trip demands in each region. We will use all historical data and AutoGluon to \n",
    "train the model. And predict the next three 24 hours trip demands in all NYC regions.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4992c4f",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "We use Amazon SageMaker to train the model. Make sure you have an SageMaker exectuion role, and have the permissions to run training jobs, and load data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4933c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define it is a production environment or sampled environment\n",
    "PROD=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faf25796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/qiaoshi/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "from ag_model import (\n",
    "    AutoGluonSagemakerEstimator,\n",
    "    AutoGluonNonRepackInferenceModel,\n",
    "    AutoGluonSagemakerInferenceModel,\n",
    "    AutoGluonRealtimePredictor,\n",
    "    AutoGluonBatchPredictor,\n",
    ")\n",
    "from sagemaker import utils\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "role = \"arn:aws:iam::178770047227:role/service-role/SageMaker-ExecutionRole-20231202T212840\" # change to your role\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session._region_name\n",
    "\n",
    "bucket = \"qiaoshi-aws-ml\"   # change to your role\n",
    "s3_prefix = f\"tlc/ml/{utils.sagemaker_timestamp()}\"\n",
    "output_path = f\"s3://{bucket}/{s3_prefix}/output/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8213590f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b453761",
   "metadata": {},
   "source": [
    "Users can create their own training/inference scripts using [SageMaker Python SDK examples](https://sagemaker.readthedocs.io/en/stable/overview.html#prepare-a-training-script).\n",
    "The scripts we created allow to pass AutoGluon configuration as a YAML file (located in `data/config` directory).\n",
    "\n",
    "We are using [official AutoGluon Deep Learning Container images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers) with custom training scripts (see `scripts/` directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da167200",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = AutoGluonSagemakerEstimator(\n",
    "    role=role,\n",
    "    entry_point=\"scripts/tabular_train.py\",\n",
    "    region=region,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.8xlarge\" if PROD else \"ml.m5.2xlarge\",\n",
    "    framework_version=\"0.8.2\",\n",
    "    py_version=\"py39\",\n",
    "    base_job_name=\"tlc-tabular-train\",\n",
    "    disable_profiler=True,\n",
    "    debugger_hook_config=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69870f34",
   "metadata": {},
   "source": [
    "Upload the scripts to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_prefix = f\"autogluon_sm/{utils.sagemaker_timestamp()}\"\n",
    "\n",
    "train_input = \"s3://qiaoshi-aws-ml/tlc/results/ml/trips_with_weather_merged/train.csv\" if PROD else \"s3://qiaoshi-aws-ml/tlc/results/ml/trips_with_weather_sampled/train.csv\"\n",
    "\n",
    "eval_input = \"s3://qiaoshi-aws-ml/tlc/results/ml/trips_with_weather_merged/eval.csv\" if PROD else \"s3://qiaoshi-aws-ml/tlc/results/ml/trips_with_weather_sampled/eval.csv\"\n",
    "\n",
    "config_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"config\", \"config-med.yaml\"), key_prefix=s3_prefix\n",
    ")\n",
    "\n",
    "# Provide inference script so the script repacking is not needed later\n",
    "# See more here: https://docs.aws.amazon.com/sagemaker/latest/dg/mlopsfaq.html\n",
    "# Q. Why do I see a repack step in my SageMaker pipeline?\n",
    "inference_script = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"scripts\", \"tabular_serve.py\"), key_prefix=s3_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f420b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fedb3195",
   "metadata": {},
   "source": [
    "### Fit The Model\n",
    "For local training set `instance_type` to local.\n",
    "\n",
    "For non-local training the recommended instance type is `ml.m5.2xlarge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ea738",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = utils.unique_name_from_base(\"tlc-training\")\n",
    "ag.fit(\n",
    "    {\n",
    "        \"config\": config_input,\n",
    "        \"train\": train_input,\n",
    "        \"test\": eval_input,\n",
    "        \"serving\": inference_script,\n",
    "    },\n",
    "    job_name=job_name,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4d57c00",
   "metadata": {},
   "source": [
    "### Model export\n",
    "\n",
    "AutoGluon models are portable: everything needed to deploy a trained model is in the tarball created by SageMaker.\n",
    "\n",
    "The artifact can be used locally, on EC2/ECS/EKS or served via SageMaker Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5dccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp {ag.model_data} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240c86b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!ls -alF model.tar.gz"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7633d597",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Endpoint Deployment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb4fb9ec",
   "metadata": {},
   "source": [
    "Upload the model we trained earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f6eaa2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.utils.unique_name_from_base(\"sagemaker-autogluon-serving-trained-model\")\n",
    "\n",
    "model_data = sagemaker_session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cbdc562",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = \"s3://sagemaker-us-east-1-178770047227/tlc-training-1705471847-f252/output/model.tar.gz\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4c9a075",
   "metadata": {},
   "source": [
    "Deploy remote or local endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa6dd02",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae49533e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoGluonNonRepackInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.8.2\",\n",
    "    py_version=\"py39\",\n",
    "    instance_type=instance_type,\n",
    "    source_dir=\"scripts\",\n",
    "    entry_point=\"tabular_serve.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50c52f09",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AutoGluonNonRepackInferenceModel.prepare_container_def() got an unexpected keyword argument 'accept_eula'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCSVSerializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Developer/sjtu/data-analytics/venv/lib/python3.11/site-packages/sagemaker/model.py:1602\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, accept_eula, endpoint_logging, resources, endpoint_type, managed_instance_scaling, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# existing single model endpoint path\u001b[39;00m\n\u001b[0;32m-> 1602\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_sagemaker_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserverless_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1608\u001b[0m     serverless_inference_config_dict \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1609\u001b[0m         serverless_inference_config\u001b[38;5;241m.\u001b[39m_to_request_dict() \u001b[38;5;28;01mif\u001b[39;00m is_serverless \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1610\u001b[0m     )\n\u001b[1;32m   1611\u001b[0m     production_variant \u001b[38;5;241m=\u001b[39m sagemaker\u001b[38;5;241m.\u001b[39mproduction_variant(\n\u001b[1;32m   1612\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1613\u001b[0m         instance_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         container_startup_health_check_timeout\u001b[38;5;241m=\u001b[39mcontainer_startup_health_check_timeout,\n\u001b[1;32m   1620\u001b[0m     )\n",
      "File \u001b[0;32m~/Developer/sjtu/data-analytics/venv/lib/python3.11/site-packages/sagemaker/model.py:857\u001b[0m, in \u001b[0;36mModel._create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags, serverless_inference_config, accept_eula)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m model_package\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 857\u001b[0m     container_def \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_container_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserverless_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_eula\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_eula\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session, PipelineSession):\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;66;03m# _base_name, model_name are not needed under PipelineSession.\u001b[39;00m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;66;03m# the model_data may be Pipeline variable\u001b[39;00m\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# which may break the _base_name generation\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_base_name_if_needed(\n\u001b[1;32m    869\u001b[0m             image_uri\u001b[38;5;241m=\u001b[39mcontainer_def[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    870\u001b[0m             script_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_dir,\n\u001b[1;32m    871\u001b[0m             model_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_model_uri(),\n\u001b[1;32m    872\u001b[0m         )\n",
      "\u001b[0;31mTypeError\u001b[0m: AutoGluonNonRepackInferenceModel.prepare_container_def() got an unexpected keyword argument 'accept_eula'"
     ]
    }
   ],
   "source": [
    "model.deploy(initial_instance_count=1, serializer=CSVSerializer(), instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30190a41-71df-4eca-a616-a32ee9b5b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = AutoGluonRealtimePredictor(model.endpoint_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52982b98",
   "metadata": {},
   "source": [
    "### Predict on unlabeled test data\n",
    "\n",
    "Remove target variable (`class`) from the data and get predictions for a sample of 100 rows using the deployed endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e3fab4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/test.csv\")\n",
    "data = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ab16a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preds = predictor.predict(data.drop(columns=\"total_trips\"))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a8ab4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = preds[[\"pred\"]]\n",
    "p = p.join(data[\"class\"]).rename(columns={\"class\": \"actual\"})\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d9dcbe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{(p.pred==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "084ee65e",
   "metadata": {},
   "source": [
    "### Cleanup Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd315e3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8197080",
   "metadata": {},
   "source": [
    "# Batch Transform\n",
    "\n",
    "Deploying a trained model to a hosted endpoint has been available in SageMaker since launch and is a great way to provide real-time predictions to a service like a website or mobile app. But, if the goal is to generate predictions from a trained model on a large dataset where minimizing latency isn’t a concern, then the batch transform functionality may be easier, more scalable, and more appropriate.\n",
    "\n",
    "[Read more about Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b607438",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = sagemaker.utils.unique_name_from_base(\n",
    "    \"sagemaker-autogluon-batch_transform-trained-model\"\n",
    ")\n",
    "\n",
    "model_data = sagemaker_session.upload_data(\n",
    "    path=os.path.join(\".\", \"model.tar.gz\"), key_prefix=f\"{endpoint_name}/models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab078513",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.m5.2xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88630d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoGluonSagemakerInferenceModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    region=region,\n",
    "    framework_version=\"0.6\",\n",
    "    py_version=\"py38\",\n",
    "    instance_type=instance_type,\n",
    "    entry_point=\"tabular_serve-batch.py\",\n",
    "    source_dir=\"scripts\",\n",
    "    predictor_cls=AutoGluonBatchPredictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276fd30b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    strategy=\"MultiRecord\",\n",
    "    max_payload=6,\n",
    "    max_concurrent_transforms=1,\n",
    "    output_path=output_path,\n",
    "    accept=\"application/json\",\n",
    "    assemble_with=\"Line\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9559625",
   "metadata": {},
   "source": [
    "Prepare data for batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dde772",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(f\"data/test.csv\")[:100].to_csv(\"data/test_no_header.csv\", header=False, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "355fabc8",
   "metadata": {},
   "source": [
    "Upload data to sagemaker session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3dbd00",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_input = transformer.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"data\", \"test_no_header.csv\"), key_prefix=s3_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21b56f5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformer.transform(\n",
    "    test_input,\n",
    "    input_filter=\"$[:14]\",  # filter-out target variable\n",
    "    split_type=\"Line\",\n",
    "    content_type=\"text/csv\",\n",
    "    output_filter=\"$['class']\",  # keep only prediction class in the output\n",
    ")\n",
    "\n",
    "transformer.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee44ccfb",
   "metadata": {},
   "source": [
    "Download batch transform outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ff698",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {transformer.output_path[:-1]}/test_no_header.csv.out ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b0953",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "p = pd.concat(\n",
    "    [\n",
    "        pd.read_json(\"test_no_header.csv.out\", orient=\"index\")\n",
    "        .sort_index()\n",
    "        .rename(columns={0: \"preds\"}),\n",
    "        pd.read_csv(\"data/test.csv\")[[\"class\"]].iloc[:100].rename(columns={\"class\": \"actual\"}),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150fa02",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{(p.preds==p.actual).astype(int).sum()}/{len(p)} are correct\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd3e9e5a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "In this tutorial we successfully trained an AutoGluon model and explored a few options how to deploy it using SageMaker. Any of the sections of this tutorial (training/endpoint inference/batch inference) can be used independently (i.e. train locally, deploy to SageMaker, or vice versa).\n",
    "\n",
    "Next steps:\n",
    "* [Learn more](https://auto.gluon.ai) about AutoGluon, explore [tutorials](https://auto.gluon.ai/stable/tutorials/index.html).\n",
    "* Explore [SageMaker inference documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html)."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
